marktWertKalk(1000, 2000)
marktWertKalk(750, 2015, 1)
marktWertKalk(750, 2015, 1)
kauf_jahr == 2015
kauf_jahr <- 2015
inflation_data[1, ] == kauf_jahr
infl_faktor <- prod((1 + inflation_data[which(inflation_data[, 1] == kauf_jahr):dim(inflation_data)[2], 2] / 100))
marktWertKalk <- function(einkaufs_wert, kauf_jahr, abschlag = 0.6){
# Inflationsrate
inflation_data <- data.frame(
year = 2000:2023,
inflation_rate = c(
1.4, 1.9, 1.3, 1.0, 1.6, 1.5, 1.6, 2.3, 2.6, 0.3,
1.1, 2.1, 2.0, 1.5, 0.9, 0.3, 0.5, 1.5, 1.8, 1.4,
0.5, 3.1, 6.9, 5.9
)
)
infl_faktor <- prod((1 + inflation_data[which(inflation_data[, 1] == kauf_jahr):dim(inflation_data)[2], 2] / 100))
return(einkaufs_wert * infl_faktor * abschlag)
}
marktWertKalk(750, 2015, 1)
marktWertKalk <- function(einkaufs_wert, kauf_jahr, abschlag = 0.6){
# Inflationsrate
inflation_data <- data.frame(
Jahr = 1990:2023,
Inflationsrate = c(
2.7, 3.5, 5.0, 4.5, 2.7, 1.9, 1.4, 1.9, 0.8, 0.7,
1.4, 1.9, 1.3, 1.0, 1.6, 1.5, 1.6, 2.3, 2.6, 0.3,
1.1, 2.1, 2.0, 1.5, 0.9, 0.3, 0.5, 1.5, 1.8, 1.4,
0.5, 3.1, 6.9, 5.9
)
)
infl_faktor <- prod((1 + inflation_data[which(inflation_data[, 1] == kauf_jahr):dim(inflation_data)[2], 2] / 100))
return(einkaufs_wert * infl_faktor * abschlag)
}
marktWertKalk(826, 1995, 1)
marktWertKalk(14425.17, 2003, 1)
marktWertKalk(22004.47, 2003, 1)
marktWertKalk(1735.18, 2003, 0.6)
marktWertKalk(523.77, 2003, 1)
return(round(einkaufs_wert * infl_faktor * abschlag), 2)
marktWertKalk <- function(einkaufs_wert, kauf_jahr, abschlag = 0.6){
# Inflationsrate
inflation_data <- data.frame(
Jahr = 1990:2023,
Inflationsrate = c(
2.7, 3.5, 5.0, 4.5, 2.7, 1.9, 1.4, 1.9, 0.8, 0.7,
1.4, 1.9, 1.3, 1.0, 1.6, 1.5, 1.6, 2.3, 2.6, 0.3,
1.1, 2.1, 2.0, 1.5, 0.9, 0.3, 0.5, 1.5, 1.8, 1.4,
0.5, 3.1, 6.9, 5.9
)
)
infl_faktor <- prod((1 + inflation_data[which(inflation_data[, 1] == kauf_jahr):dim(inflation_data)[2], 2] / 100))
return(round(einkaufs_wert * infl_faktor * abschlag), 2)
}
marktWertKalk(523.77, 2003, 1)
marktWertKalk <- function(einkaufs_wert, kauf_jahr, abschlag = 0.6){
# Inflationsrate
inflation_data <- data.frame(
Jahr = 1990:2023,
Inflationsrate = c(
2.7, 3.5, 5.0, 4.5, 2.7, 1.9, 1.4, 1.9, 0.8, 0.7,
1.4, 1.9, 1.3, 1.0, 1.6, 1.5, 1.6, 2.3, 2.6, 0.3,
1.1, 2.1, 2.0, 1.5, 0.9, 0.3, 0.5, 1.5, 1.8, 1.4,
0.5, 3.1, 6.9, 5.9
)
)
infl_faktor <- prod((1 + inflation_data[which(inflation_data[, 1] == kauf_jahr):dim(inflation_data)[2], 2] / 100))
return(round(einkaufs_wert * infl_faktor * abschlag, 2))
}
marktWertKalk(523.77, 2003, 1)
marktWertKalk(53714.52, 2003, 1)
1000 * 1000 * 5000 > 100000000
??qtr2month
citation(elasticnet)
citation("elasticnet")
library(reticulate)
reticulate::use_python("C:/Program Files/Python313/python.exe")
reticulate::repl_python()
reticulate::repl_python()
library(reticulate)
reticulate::use_python("C:/Program Files/Python313/python.exe")
reticulate::repl_python()
library(TwoStepSDFM)
library(testthat)
# Simulate a DGP using simFM
set.seed(02102025)
no_of_observations <- 102 + 3# Number of observations
no_of_variables <- 50 # Number of variabes
no_of_factors <- 2 # Number of factors
trans_error_var_cov <- diag(1, no_of_factors) # Variance-covariance matrix of the transition errors
loading_matrix <- matrix(round(rnorm(no_of_variables * no_of_factors)), no_of_variables, no_of_factors) # Factor loadings matrix
meas_error_mean <- rep(0, no_of_variables) # Mean of the measurement error
meas_error_var_cov <- diag(1, no_of_variables) # Variance-covariance matrix of the measurement error
trans_var_coeff <- cbind(diag(0.5, no_of_factors), -diag(0.25, no_of_factors)) # Factor VAR coefficient matrix
factor_lag_order <- 2 # Order of the factor VAR process
simul_delay <- c(3, floor(rexp(no_of_variables - 1, 1)))
quarterfy <- TRUE # Indicating whether or not some of the variables should be aggregated to quarterly observations (i.e., quarterfied)
quarterly_variable_ratio  <- 1/no_of_variables
corr <- TRUE # Indicating whether or not the measurement error should be internatlly cross-crossectionally correlated
beta_param <- 2 # Beta parameter governing the degree of correlation of the measurement error
seed <- 01102025 # Seed
set.seed(seed)
burn_in <- 999 # Burn-in period
starting_date <- "1970-01-01"
rescale <- TRUE # Indicating whether the variance of the measurement error should be scaled according to the variance of the common-component
check_stationarity <- TRUE
stationarity_check_threshold <- 1e-10
# Draw the FM object
is_FM <- simFM(no_of_observations = no_of_observations, no_of_variables = no_of_variables,
no_of_factors = no_of_factors, loading_matrix = loading_matrix,
meas_error_mean = meas_error_mean, meas_error_var_cov = meas_error_var_cov,
trans_error_var_cov = trans_error_var_cov, trans_var_coeff = trans_var_coeff,
factor_lag_order = factor_lag_order, delay = simul_delay, quarterfy = quarterfy,
quarterly_variable_ratio  = quarterly_variable_ratio, corr = corr,
beta_param = beta_param, seed = seed, burn_in = burn_in, starting_date = starting_date,
rescale = rescale, check_stationarity = check_stationarity,
stationarity_check_threshold = stationarity_check_threshold)
data <- is_FM$data
variable_of_interest <- 1
fcast_horizon <- 0
delay <- simul_delay
frequency <- is_FM$frequency
no_of_factors <- 3
seed <- 09102025
min_ridge_penalty <- 0.01
max_ridge_penalty <- 1
lasso_penalty_type <- "selected"
min_max_penalty <- c(10, no_of_variables - 1)
# min_max_penalty <- c(10, 50 * (no_of_variables - 1))
# min_max_penalty <- c(0.0001, 10)
cv_repititions <- 3
cv_size <- 100
max_factor_lag_order = 10
decorr_errors = TRUE
lag_estim_criterion = "BIC"
ridge_penalty = 1e-6
lasso_penalty = NULL
max_iterations = 100
max_no_steps = NULL
comp_null = 1e-15
check_rank = FALSE
conv_crit = 1e-4
conv_threshold = 1e-4
log = FALSE
parallel = TRUE
max_ar_lag_order = 5
max_predictor_lag_order = 5
expect_no_error(crossVal(data = data, variable_of_interest = variable_of_interest, fcast_horizon = fcast_horizon,
delay = delay, frequency = frequency, no_of_factors = no_of_factors,
seed = seed, min_ridge_penalty = min_ridge_penalty, max_ridge_penalty = max_ridge_penalty,
cv_repititions = cv_repititions, cv_size = cv_size, lasso_penalty_type = lasso_penalty_type,
min_max_penalty = min_max_penalty, parallel = TRUE))
########################################################################################################################
############ Cleaning the data for the empirical application ###########################################################
############ Domenic Franjic ###########################################################################################
############ 15.09.2025; Version 0.0.1 #################################################################################
########################################################################################################################
library(rstudioapi) # Navigate directories from R more easily
library(zoo) # Handle time series
library(lubridate) # Also handle time series because its fun
library(BVAR) # Transform fred data
library(nowcasting) # Used for turning quarterly vectors to monthlys
library(readxl)
library(alfred) # Access ALFRED vintages
library(TwoStepSDFM)
# Empty environment
rm(list = ls())
# Set WD to file lovation
setwd(dirname(getActiveDocumentContext()$path))
# Extract the names of the series contained in FRED-QD
quarterly_series_trans <- read.csv("./Historical vintages of FRED-QD 2018-05 to 2024-12/FRED-QD_2024m12.csv")[2, -1]
quarterly_series_names <- colnames(quarterly_series_trans)
false_final_substr_ind <- which(substr(quarterly_series_names, nchar(quarterly_series_names), nchar(quarterly_series_names)) %in% "x")
quarterly_series_names[false_final_substr_ind] <- substr(quarterly_series_names[false_final_substr_ind], 1, nchar(quarterly_series_names[false_final_substr_ind]) - 1)
colnames(quarterly_series_trans) <- quarterly_series_names
# Loop over files in folder #
monthly_file_list <- list.files(path="./Historical-vintages-of-FRED-MD-2015-01-to-2024-12", pattern="*.csv", full.names=TRUE, recursive=FALSE)
pb = txtProgressBar(min = 0, max = length(monthly_file_list), initial = 0, style = 3)
step <- 0
file_name <- monthly_file_list[1] # For debugging
# Nowcast
vintage_file_list <- list.files(path="../Data/FREDGDP_Real_Time", full.names = TRUE, recursive = FALSE)
vintage_name <- vintage_file_list[1]
data <- read.table(paste0(vintage_name, "/data.csv"), sep = ",", header = FALSE)
data_scaled <- scale(data)
scaling <- attributes(data_scaled)$`scaled:scale`
centering <- attributes(data_scaled)$`scaled:center`
delay <- unlist(read.table(paste0(vintage_name, "/delay.csv"), sep = ",", header = FALSE))
frequency <- unlist(read.table(paste0(vintage_name, "/frequency.csv"), sep = ",", header = FALSE))
names <- unlist(read.table(paste0(vintage_name, "/names.csv"), sep = ",", header = FALSE))
dates <- as.Date(unlist(read.table(paste0(vintage_name, "/dates.csv"), sep = ",", header = FALSE)))
no_of_obs <- dim(data)[1]
no_of_factors <- 1
data_zoo <- as.zoo(ts(data_scaled, end = c(year(dates[no_of_obs]), month(dates[no_of_obs])),
frequency = 12))
colnames(data_zoo) <- names
check_fit <- TwoStepSDFM::twoStepSDFM(data = data_zoo[, which(frequency == 12)], delay = delay[which(frequency == 12)],
selected = rep(floor(0.90 * sum(frequency == 12)), no_of_factors),
no_of_factors = no_of_factors)
fit_plots <- plot(check_fit)
fit_plots$`Factor Time Series Plots`
fit_plots$`Loading Matrix Heatmap`
fit_plots$`Meas. Error Var.-Cov. Matrix Heatmap`
variables_of_interest <- which(colnames(data_zoo) == "GDP")
check_nowcast <- TwoStepSDFM::nowcast(data = data_zoo, variables_of_interest = variables_of_interest,
max_fcast_horizon = 4, delay = delay,
selected = rep(floor(0.90 * sum(frequency == 12)), no_of_factors),
frequency = frequency, no_of_factors = no_of_factors
)
nowcast_plot <- plot.SDFMnowcast(check_nowcast)
nowcast_plot <- plot(check_nowcast)
nowcast_plot$`Single Pred. Fcast Density Plots GDP`
nowcast_plot$`Factor Time Series Plots`
nowcast_plot$`Loading Matrix Heatmap`
nowcast_plot$`Meas. Error Var.-Cov. Matrix Heatmap`
?crossVal
variables_of_interest
TwoStepSDFM::crossVal(data = data_zoo, variable_of_interest = variables_of_interest,
fcast_horizon = 0, delay = delay, frequency = frequency,
no_of_factors = no_of_factors, seed = 16102025, min_ridge_penalty = 0.01,
max_ridge_penalty = 10, cv_repititions = 3, cv_size = 1000,
lasso_penalty_type = "selected", min_max_penalty = c(10, sum(frequency == 12)),
pasrallel = TRUE)
cv_results <- crossVal(data = data_zoo, variable_of_interest = variables_of_interest,
fcast_horizon = 0, delay = delay, frequency = frequency,
no_of_factors = no_of_factors, seed = 16102025, min_ridge_penalty = 0.01,
max_ridge_penalty = 10, cv_repititions = 3, cv_size = 1000,
lasso_penalty_type = "selected", min_max_penalty = c(10, sum(frequency == 12)),
parallel = TRUE)
cv_results
cv_result_plots <- plot(cv_results)
cv_result_plots$`CV Results`
cv_result_plots$`BIC Results`
#' @name plot.SDFMcrossVal
#' @title Generic plotting function for SDFMnowcast S3 objects
#' @param x `SDFMcrossVal` object.
#' @param ... Additional parameters for the plotting functions.
#' @export
plot.SDFMcrossVal <- function(x, ...) {
out_list <- list()
# Plot depending on which stopping criterion has been used
if(any(grepl("Lasso", colnames(x$CV$`CV Results`), ignore.case = FALSE))){
# Cross-validation results
cv_data <- data.frame(x$CV$`CV Results`, check.names = FALSE)
cv_data$`Lasso Penalties` <- c(NaN)
for(i in 1:dim(cv_data)[1]){
cv_data$`Lasso Penalties`[i] <- paste0("(",
paste0(sprintf("%.2f", cv_data[i, 3:(dim(cv_data)[2] - 1)]), collapse = ";"),
")")
}
avg_lasso_penalty <- rowMeans(cv_data[, 3:(dim(cv_data)[2] - 1), drop = FALSE])
breaks <- seq(from = min(avg_lasso_penalty, na.rm = TRUE),
to = max(avg_lasso_penalty, na.rm = TRUE),
length.out = 6)
breaks[length(breaks)] <- breaks[length(breaks)] + 0.000006
labels <- paste0("[", sprintf("%.2f", floor(breaks[1:5] / 0.01) * 0.01),
", ",
sprintf("%.2f", floor(breaks[2:6] / 0.01) * 0.01),
")")
labels[5] <- paste0("[", sprintf("%.2f", floor(breaks[5] / 0.01) * 0.01),
", ",
sprintf("%.2f", floor(breaks[6] / 0.01) * 0.01),
"]")
binned_data_equal_width <- cut(avg_lasso_penalty,
breaks = breaks,
right = FALSE,
include.lowest = TRUE,
labels = labels)
cv_data$`Avg. Lasso Penalty` <- as.factor(binned_data_equal_width)
best_combo <- cv_data$`Lasso Penalties`[which.min(cv_data$`CV Errors`)]
best_ridge <- cv_data$`Ridge Penalty`[which.min(cv_data$`CV Errors`)]
best_cv_error <- min(cv_data$`CV Errors`)
y_min_limit <- best_cv_error
y_max_limit <- max(cv_data$`CV Errors`)
out_list$`CV Results` <- ggplot(cv_data, aes(x = `Ridge Penalty`, y = `CV Errors`, colour = `Avg. Lasso Penalty`,
shape = `Avg. Lasso Penalty`)) +
geom_point(size = 2) +
geom_hline(yintercept = cv_data$`CV Errors`[1], colour = "black") +
scale_colour_manual(values =  c("#88CCEE", "#44799E", "#000000", "#41784A", "#117733"),
name = "Avg. Lasso Penalty") +
scale_shape_discrete(name = "Avg. Lasso Penalty") +
geom_point(data = subset(cv_data, `CV Errors` == min(`CV Errors`)), aes(x = `Ridge Penalty`, y = `CV Errors`),
colour = "black", fill = "#882255", size = 3, shape = 22) +
scale_y_continuous(trans = "log10", limits = c(y_min_limit, y_max_limit)) +
scale_x_continuous(trans = "log10") +
annotate("text",  x = best_ridge, y = best_cv_error,
label = best_combo, angle = 0, vjust = 1.6, hjust = 1, size = 4, color = "darkred") +
labs(x = "log Ridge Penalty",
y = "log CV Error") +
theme_minimal()
# BIC results
bic_data <- data.frame(x$BIC$`BIC Results`, check.names = FALSE)
bic_data$`Lasso Penalties` <- c(NaN)
for(i in 1:dim(bic_data)[1]){
bic_data$`Lasso Penalties`[i] <- paste0("(",
paste0(sprintf("%.2f", bic_data[i, 3:(dim(bic_data)[2] - 1)]), collapse = ";"),
")")
}
bic_data$`Avg. Lasso Penalty` <- as.factor(binned_data_equal_width)
best_bic_combo <- bic_data$`Lasso Penalties`[which.min(bic_data$`BIC`)]
best_bic_ridge <- bic_data$`Ridge Penalty`[which.min(bic_data$`BIC`)]
best_bic <- min(bic_data$`BIC`)
y_bic_min_limit <- best_cv_error
y_bic_max_limit <- max(bic_data$`BIC`)
out_list$`BIC Results` <- ggplot(bic_data, aes(x = `Ridge Penalty`, y = `BIC`, colour = `Avg. Lasso Penalty`,
shape = `Avg. Lasso Penalty`)) +
geom_point(size = 2) +
geom_hline(yintercept = bic_data$BIC[1], colour = "black") +
scale_colour_manual(values =  c("#88CCEE", "#44799E", "#000000", "#41784A", "#117733"),
name = "Avg. Lasso Penalty") +
scale_shape_discrete(name = "Avg. Lasso Penalty") +
geom_point(data = subset(bic_data, `BIC` == min(`BIC`)), aes(x = `Ridge Penalty`, y = `BIC`),
colour = "black", fill = "#882255", size = 3, shape = 22) +
scale_y_continuous(limits = c(y_bic_min_limit, y_bic_max_limit)) +
scale_x_continuous(trans = "log10") +
annotate("text",  x = best_bic_ridge, y = best_bic,
label = best_bic_combo, angle = 0, vjust = 1.6, hjust = 1, size = 4, color = "darkred") +
labs(x = "log Ridge Penalty",
y = "BIC") +
theme_minimal()
}else if(any(grepl("# non-zero Loadings", colnames(x$CV$`CV Results`), ignore.case = FALSE))){
cv_data <- data.frame(x$CV$`CV Results`, check.names = FALSE)
cv_data$`# non-zero Loadings` <- c(NaN)
for(i in 1:dim(cv_data)[1]){
cv_data$`# non-zero Loadings`[i] <- paste0("(",
paste0(cv_data[i, 3:(dim(cv_data)[2] - 1)], collapse = ";"),
")")
}
sparsity_ratios <- 1 - rowSums(cv_data[, 3:(dim(cv_data)[2] - 1), drop = FALSE]) / rowSums(cv_data[1, 3:(dim(cv_data)[2] - 1), drop = FALSE])
breaks <- seq(from = min(sparsity_ratios, na.rm = TRUE),
to = max(sparsity_ratios, na.rm = TRUE),
length.out = 6)
breaks[length(breaks)] <- breaks[length(breaks)] + 0.000006
labels <- paste0("[", sprintf("%.2f", floor(breaks[1:5] / 0.01) * 0.01),
", ",
sprintf("%.2f", floor(breaks[2:6] / 0.01) * 0.01),
")")
labels[5] <- paste0("[", sprintf("%.2f", floor(breaks[5] / 0.01) * 0.01),
", ",
sprintf("%.2f", floor(breaks[6] / 0.01) * 0.01),
"]")
binned_data_equal_width <- cut(sparsity_ratios,
breaks = breaks,
right = FALSE,
include.lowest = TRUE,
labels = labels)
cv_data$`Sparsity Ratio` <- as.factor(binned_data_equal_width)
best_combo <- cv_data$`# non-zero Loadings`[which.min(cv_data$`CV Errors`)]
best_ridge <- cv_data$`Ridge Penalty`[which.min(cv_data$`CV Errors`)]
best_cv_error <- min(cv_data$`CV Errors`)
y_min_limit <- best_cv_error
y_max_limit <- max(cv_data$`CV Errors`)
out_list$`CV Results` <- ggplot(cv_data, aes(x = `Ridge Penalty`, y = `CV Errors`, colour = `Sparsity Ratio`,
shape = `Sparsity Ratio`)) +
geom_point(size = 2) +
geom_hline(yintercept = cv_data$`CV Errors`[1], colour = "black") +
scale_colour_manual(values =  c("#88CCEE", "#44799E", "#000000", "#41784A", "#117733"),
name = "Sparsity Ratio") +
scale_shape_discrete(name = "Sparsity Ratio") +
geom_point(data = subset(cv_data, `CV Errors` == min(`CV Errors`)), aes(x = `Ridge Penalty`, y = `CV Errors`),
colour = "black", fill = "#882255", size = 3, shape = 22) +
scale_y_continuous(trans = "log10", limits = c(y_min_limit, y_max_limit)) +
scale_x_continuous(trans = "log10") +
annotate("text",  x = best_ridge, y = best_cv_error,
label = best_combo, angle = 0, vjust = 1.6, hjust = 1, size = 4, color = "darkred") +
labs(x = "log Ridge Penalty",
y = "log CV Error") +
theme_minimal()
# BIC results
bic_data <- data.frame(x$BIC$`BIC Results`, check.names = FALSE)
bic_data$`# non-zero Loadings` <- c(NaN)
for(i in 1:dim(bic_data)[1]){
bic_data$`# non-zero Loadings`[i] <- paste0("(",
paste0(sprintf("%.0f", bic_data[i, 3:(dim(bic_data)[2] - 1)]), collapse = ";"),
")")
}
bic_data$`Sparsity Ratio` <- as.factor(binned_data_equal_width)
best_bic_combo <- bic_data$`# non-zero Loadings`[which.min(bic_data$`BIC`)]
best_bic_ridge <- bic_data$`Ridge Penalty`[which.min(bic_data$`BIC`)]
best_bic <- min(bic_data$`BIC`)
y_bic_min_limit <- best_cv_error
y_bic_max_limit <- max(bic_data$`BIC`)
out_list$`BIC Results` <- ggplot(bic_data, aes(x = `Ridge Penalty`, y = `BIC`, colour = `Sparsity Ratio`,
shape = `Sparsity Ratio`)) +
geom_point(size = 2) +
geom_hline(yintercept = bic_data$BIC[1], colour = "black") +
scale_colour_manual(values =  c("#88CCEE", "#44799E", "#000000", "#41784A", "#117733"),
name = "Sparsity Ratio") +
scale_shape_discrete(name = "Sparsity Ratio") +
geom_point(data = subset(bic_data, `BIC` == min(`BIC`)), aes(x = `Ridge Penalty`, y = `BIC`),
colour = "black", fill = "#882255", size = 3, shape = 22) +
scale_y_continuous(limits = c(y_bic_min_limit, y_bic_max_limit)) +
scale_x_continuous(trans = "log10") +
annotate("text",  x = best_bic_ridge, y = best_bic,
label = best_bic_combo, angle = 0, vjust = 1.6, hjust = 1, size = 4, color = "darkred") +
labs(x = "log Ridge Penalty",
y = "BIC") +
theme_minimal()
}else if(any(grepl("Maximum No. of LARS Steps", colnames(x$CV$`CV Results`), ignore.case = FALSE))){
cv_data <- data.frame(x$CV$`CV Results`, check.names = FALSE)
breaks <- floor(seq(from = min(cv_data$`Maximum No. of LARS Steps`, na.rm = TRUE),
to = max(cv_data$`Maximum No. of LARS Steps`, na.rm = TRUE),
length.out = 6))
breaks[length(breaks)] <- breaks[length(breaks)] + 0.000006
labels <- paste0("[", sprintf("%.0f", floor(breaks[1:5] / 0.01) * 0.01),
", ",
sprintf("%.0f", floor(breaks[2:6] / 0.01) * 0.01),
")")
labels[5] <- paste0("[", sprintf("%.0f", floor(breaks[5] / 0.01) * 0.01),
", ",
sprintf("%.0f", floor(breaks[6] / 0.01) * 0.01),
"]")
binned_data_equal_width <- cut(cv_data$`Maximum No. of LARS Steps`,
breaks = breaks,
right = FALSE,
include.lowest = TRUE,
labels = labels)
cv_data$`# of LARS Steps` <- as.factor(binned_data_equal_width)
best_combo <- cv_data$`Maximum No. of LARS Steps`[which.min(cv_data$`CV Errors`)]
best_ridge <- cv_data$`Ridge Penalty`[which.min(cv_data$`CV Errors`)]
best_cv_error <- min(cv_data$`CV Errors`)
y_min_limit <- best_cv_error
y_max_limit <- max(cv_data$`CV Errors`)
out_list$`CV Results` <- ggplot(cv_data, aes(x = `Ridge Penalty`, y = `CV Errors`, colour = `# of LARS Steps`,
shape = `# of LARS Steps`)) +
geom_point(size = 2) +
geom_hline(yintercept = cv_data$`CV Errors`[1], colour = "black") +
scale_colour_manual(values =  c("#88CCEE", "#44799E", "#000000", "#41784A", "#117733"),
name = "# of LARS Steps") +
scale_shape_discrete(name = "# of LARS Steps") +
geom_point(data = subset(cv_data, `CV Errors` == min(`CV Errors`)), aes(x = `Ridge Penalty`, y = `CV Errors`),
colour = "black", fill = "#882255", size = 3, shape = 22) +
scale_y_continuous(trans = "log10", limits = c(y_min_limit, y_max_limit)) +
scale_x_continuous(trans = "log10") +
annotate("text",  x = best_ridge, y = best_cv_error,
label = best_combo, angle = 0, vjust = 1.6, hjust = 1, size = 4, color = "darkred") +
labs(x = "log Ridge Penalty",
y = "log CV Error") +
theme_minimal()
# BIC results
bic_data <- data.frame(x$BIC$`BIC Results`, check.names = FALSE)
bic_data$`# of LARS Steps` <- as.factor(binned_data_equal_width)
best_bic_combo <- bic_data$`Maximum No. of LARS Steps`[which.min(bic_data$`BIC`)]
best_bic_ridge <- bic_data$`Ridge Penalty`[which.min(bic_data$`BIC`)]
best_bic <- min(bic_data$`BIC`)
y_bic_min_limit <- best_cv_error
y_bic_max_limit <- max(bic_data$`BIC`)
out_list$`BIC Results` <- ggplot(bic_data, aes(x = `Ridge Penalty`, y = `BIC`, colour = `# of LARS Steps`,
shape = `# of LARS Steps`)) +
geom_point(size = 2) +
geom_hline(yintercept = bic_data$BIC[1], colour = "black") +
scale_colour_manual(values =  c("#88CCEE", "#44799E", "#000000", "#41784A", "#117733"),
name = "# of LARS Steps") +
scale_shape_discrete(name = "# of LARS Steps") +
geom_point(data = subset(bic_data, `BIC` == min(`BIC`)), aes(x = `Ridge Penalty`, y = `BIC`),
colour = "black", fill = "#882255", size = 3, shape = 22) +
scale_y_continuous(limits = c(y_bic_min_limit, y_bic_max_limit)) +
scale_x_continuous(trans = "log10") +
annotate("text",  x = best_bic_ridge, y = best_bic,
label = best_bic_combo, angle = 0, vjust = 1.6, hjust = 1, size = 4, color = "darkred") +
labs(x = "log Ridge Penalty",
y = "BIC") +
theme_minimal()
}
return(out_list)
}
cv_result_plots <- plot.SDFMcrossVal(cv_results)
library(ggplot2)
cv_result_plots <- plot.SDFMcrossVal(cv_results)
cv_result_plots$`CV Results`
cv_result_plots$`BIC Results`
cv_results$CV$`Min. CV`
nocast_cv <-   check_nowcast <- TwoStepSDFM::nowcast(data = data_zoo, variables_of_interest = variables_of_interest,
max_fcast_horizon = 4, delay = delay,
selected = cv_results$CV$`Min. CV`[3:(3 + no_of_factors - 1)], no_of_factors),
cv_results$CV$`Min. CV`[3:(3 + no_of_factors - 1)]
nocast_cv <-   check_nowcast <- TwoStepSDFM::nowcast(data = data_zoo, variables_of_interest = variables_of_interest,
max_fcast_horizon = 4, delay = delay,
selected = cv_results$CV$`Min. CV`[3:(3 + no_of_factors - 1)],
frequency = frequency, no_of_factors = no_of_factors
)
nocast_cv
nocast_cv$`SDFM Fit`
nocast_cv <-   check_nowcast <- TwoStepSDFM::nowcast(data = data_zoo, variables_of_interest = variables_of_interest,
max_fcast_horizon = 4, delay = delay,
selected = cv_results$CV$`Min. CV`[3:(3 + no_of_factors - 1)],
frequency = frequency, no_of_factors = no_of_factors
)
nocast_cv
nocast_bic <-   check_nowcast <- TwoStepSDFM::nowcast(data = data_zoo, variables_of_interest = variables_of_interest,
max_fcast_horizon = 4, delay = delay,
selected = cv_results$BIC$`Min. BIC`[3:(3 + no_of_factors - 1)],
frequency = frequency, no_of_factors = no_of_factors
)
cv_results$BIC$`Min. BIC`[3:(3 + no_of_factors - 1)]
nocast_bic
nocast_cv
# Load libraries
library(rstudioapi)
library(roxygen2)
# Set directory
setwd(dirname(getActiveDocumentContext()$path))
rm(list = ls())
# Load libraries
library(rstudioapi)
library(roxygen2)
# Set directory
setwd(dirname(getActiveDocumentContext()$path))
rm(list  = ls())
# Build
devtools::build()
