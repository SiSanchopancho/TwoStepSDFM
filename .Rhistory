# Mishandling max_predictor_lag_order
max_predictor_lag_order <- checkPositiveSignedInteger(max_predictor_lag_order , "max_predictor_lag_order ")
if(month(time(data))[dim(data)[1]] %in% c(3, 6, 9, 12)){
fcast_horizon <- 0
target_variable_delay <- delay[variables_of_interest]
quarterly_delay <- delay[which(frequency == 4)[-variables_of_interest]]
effective_fcast_horizon <- max_fcast_horizon
}else if(month(time(data))[dim(data)[1]] %in% c(1, 4, 7, 10)){
fcast_horizon <- 2
target_variable_delay <- delay[variables_of_interest] + 3
quarterly_delay <- delay[which(frequency == 4)[-variables_of_interest]] + 3
effective_fcast_horizon <- max_fcast_horizon - 1
}else if(month(time(data))[dim(data)[1]] %in% c(2, 5, 8, 11)){
fcast_horizon <- 1
target_variable_delay <- delay[variables_of_interest] + 3
quarterly_delay <- delay[which(frequency == 4)[-variables_of_interest]] + 3
effective_fcast_horizon <- max_fcast_horizon - 1
}
SDFM_fit <- twoStepSDFM(data = data[, which(frequency == 12)], delay = delay[which(frequency == 12)],
selected = selected,  no_of_factors = no_of_factors,
max_factor_lag_order = max_factor_lag_order,
decorr_errors = decorr_errors, lag_estim_criterion = lag_estim_criterion,
ridge_penalty = ridge_penalty,  lasso_penalty = lasso_penalty,
max_iterations = max_iterations, max_no_steps = max_no_steps,
comp_null = comp_null, check_rank = check_rank, conv_crit = conv_crit,
conv_threshold = conv_threshold, log = log, parallel = parallel,
fcast_horizon = fcast_horizon
)
# Prepare the data-set for the forecasting wrapper
factor_ts <- SDFM_fit$smoothed_factors
column_names <- c(colnames(data)[which(frequency == 4)], paste0("Factor ", 1:no_of_factors))
fcast_data <- merge.zoo(data[, which(frequency == 4)], factor_ts)
colnames(fcast_data) <- column_names
# If data does not start at the second month of the first quarter
#   available, add observations at the beginning of the panel:
#   This convention is necessary for the aggregation scheme inside
#   the forecastWrapper for the quarterly data. (see Mariano, R. S., & Murasawa,
#   Y. (2003). A new coincident index of business cycles based on monthly and
#   quarterly series. Journal of applied Econometrics, 18(4), 427-443.)
if(!(month(time(fcast_data))[1] %in% c(2, 5, 8, 11))){
temp_times <- time(fcast_data)[1]
temp_data <- coredata(fcast_data)
if(month(time(fcast_data))[1] %in% c(1, 4, 7, 10)){
temp_data <- rbind(matrix(NaN, 2, dim(temp_data)[2]), temp_data)
temp_start <- as.Date(time(fcast_data)[1]) %m-% months(2)
fcast_data <- as.zoo(ts(temp_data, start = c(year(temp_start), month(temp_start)), frequency = 12))
colnames(fcast_data) <- column_names
new_no_of_obs <- no_of_observations + 2
}else if(month(time(fcast_data))[1] %in% c(3, 6, 9, 12)){
temp_data <- rbind(matrix(NaN, 1, dim(temp_data)[2]), temp_data)
temp_start <- as.Date(time(fcast_data)[1]) %m-% months(1)
fcast_data <- as.zoo(ts(temp_data, start = c(year(temp_start), month(temp_start)), frequency = 12))
colnames(fcast_data) <- column_names
new_no_of_obs <- no_of_observations + 1
}
}
# Split the data set into target variables, quarterly predictors and monthly predictors
modiffied_data <- t(coredata(fcast_data))
target_variables <- modiffied_data[variables_of_interest, , drop = FALSE]
quarterly_predictor_ind <- delay[which(frequency == 4)][-variables_of_interest]
if(length(quarterly_predictor_ind) == 0){
quarterly_predictors <- NULL
}else{
quarterly_predictors <- modiffied_data[which(frequency == 4)[-variables_of_interest], ]
}
factors <- modiffied_data[(dim(modiffied_data)[1] - no_of_factors + 1):(dim(modiffied_data)[1]), , drop = FALSE]
#' @name importsHelper
#' ## usethis namespace: start
#' @importFrom Rcpp sourceCpp
#' @import zoo
#' @import xts
#' @import lubridate
#' @import ggplot2
#' @import stats
#' @import utils
#' @useDynLib TwoStepSDFM
## usethis namespace: end
NULL
# SPDX-License-Identifier: GPL-3.0-or-later
#
#  Copyright \u00A9 2024 Domenic Franjic
#
#  This file is part of TwoStepSDFM.
#
#  TwoStepSDFM is free software: you can redistribute
#  it and/or modify it under the terms of the GNU General Public License as
#  published by the Free Software Foundation, either version 3 of the License,
#  or (at your option) any later version.
#
#  TwoStepSDFM is distributed in the hope that it
#  will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
#  of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with TwoStepSDFM. If not, see <https://www.gnu.org/licenses/>.
#' @name forecastWrapper
#' @title Internal forecasting wrapper function
#' @description
#' This function is for internal use only and may change in future releases
#' without notice. Users should use `nowcast()` instead for a stable and
#' supported interface.
#' Helper function to check parameter vectors for positive signed integer values
#' @keywords internal
forecastWrapper <- function(target_variables,
quarterly_predictors,
factors,
target_variable_delay,
quarterly_delay,
lag_estim_criterion,
max_fcast_horizon,
max_ar_lag_order,
max_predictor_lag_order
)
{
no_of_factors <- dim(factors)[1]
no_of_target_vars <- dim(target_variables)[1]
qtrly_predictors_missing <- is.null(quarterly_predictors)
if(qtrly_predictors_missing){
no_of_qrtly_vars <- 0
}else{
no_of_qrtly_vars <- dim(quarterly_predictors)[1]
}
no_of_vars  <- no_of_qrtly_vars + no_of_target_vars
no_of_qrtly_obs <- (dim(factors)[2] - 2) / 3
min_fcast_horizons <- ifelse(target_variable_delay == 0,
1,
-floor(target_variable_delay / 3) + 1)
return_object <- list()
# Store all monthly predictors and the monthly factors in a single matrix
all_qtrly_data_delay <- c(floor(c(target_variable_delay, quarterly_delay) / 3), rep(0, no_of_factors))
# Start quarterfication loop according to Mariano and Murasawa #
# Note: It is implicitly assumed that the stationary monthly data starts at the
#   second month of the first quarter. Further, it is assumed that the data set
#   ends with an observation in the last month of the quarter. This is handled
#   by the higher level function calling this wrapper.
all_qrtly_data <- matrix(NaN, no_of_vars + no_of_factors, no_of_qrtly_obs)
for(t in seq(5, dim(factors)[2], 3)){
all_qrtly_data[1:no_of_target_vars, (t - 2)/3] <- target_variables[, t]
if(!qtrly_predictors_missing){
all_qrtly_data[(no_of_target_vars + 1):(no_of_target_vars + no_of_qrtly_vars),
(t - 2)/3] <- quarterly_predictors[, t]
}
all_qrtly_data[(no_of_target_vars + no_of_qrtly_vars + 1):(no_of_vars + no_of_factors),
(t - 2)/3] <- rowSums(cbind(1/3 * factors[, t, drop = FALSE],
2/3 * factors[, t - 1, drop = FALSE],
1 * factors[, t - 2, drop = FALSE],
2/3 * factors[, t - 3, drop = FALSE],
1/3 * factors[, t - 4, drop = FALSE]),
na.rm = TRUE)
}
# End quarterfication loop according to Mariano and Murasawa #
# Start ARDL estimation loop over the target variables #
fcasts <- matrix(NaN, no_of_target_vars, max_fcast_horizon - min(min_fcast_horizons) + 1)
for(current_target in 1:no_of_target_vars){
# Start ARDL estimation loop over the predictor #
current_fcasts <- matrix(NaN, no_of_vars + no_of_factors, max_fcast_horizon - min_fcast_horizons[current_target] + 1)
for(current_predictor in 1:(no_of_vars + no_of_factors)){
if(current_target == current_predictor){
next # Skip using the current target_variable as a single predictor as its always included as predictor
}
if(all_qtrly_data_delay[current_target] < all_qtrly_data_delay[current_predictor]){
next # Skip a predictor if it is dalyed further back compared to the target variable (we do not expect forecasting gains from using variables that are further behind then the target)
}
rel_fcast_horizons <- min_fcast_horizons[current_target]:max_fcast_horizon + all_qtrly_data_delay[current_predictor]
for(h in rel_fcast_horizons){
# Fit the model for the specific forecasting horizon
horizon_adjustment <- which(rel_fcast_horizons == h)
horizon_specific_target <- matrix(
all_qrtly_data[current_target,
(horizon_adjustment + 1):(no_of_qrtly_obs - all_qtrly_data_delay[current_target])],
ncol = 1)
horizon_specific_ar_lag <- matrix(
all_qrtly_data[current_target,
1:(no_of_qrtly_obs - all_qtrly_data_delay[current_target] - horizon_adjustment)],
ncol = 1)
horizon_specific_predictor <- matrix(
all_qrtly_data[current_predictor,
(horizon_adjustment + 1 - h):(no_of_qrtly_obs - all_qtrly_data_delay[current_target] - h)],
ncol = 1)
ardl_fit <- runARDL(horizon_specific_target,
horizon_specific_ar_lag,
horizon_specific_predictor,
max(max_ar_lag_order - max(h, 0), 1),
max(max_predictor_lag_order - max(h, 0), 1),
lag_estim_criterion)
# Forecast
forecast_predictors <- matrix(1, sum(ardl_fit$optimL_lag_order) + 3, 1) # Add three for the intercept and the "contemporaenous" observations
forecast_predictors[2:(ardl_fit$optimL_lag_order[1] + 2), ] <-
head(all_qrtly_data[current_target,
(no_of_qrtly_obs - all_qtrly_data_delay[current_target]):1],
ardl_fit$optimL_lag_order[1] + 1)
forecast_predictors[(ardl_fit$optimL_lag_order[1] + 3):(ardl_fit$optimL_lag_order[1] + ardl_fit$optimL_lag_order[2] + 3), ] <-
head(all_qrtly_data[current_predictor,
(no_of_qrtly_obs - all_qtrly_data_delay[current_predictor]):1],
ardl_fit$optimL_lag_order[2] + 1)
current_fcasts[current_predictor, which(rel_fcast_horizons == h)] <-
matrix(ardl_fit$coefficients, nrow = 1) %*% forecast_predictors
}
# End loop over the forecasting horizons #
}
# Store the final point forecast using simple forecast averaging for each target
if(qtrly_predictors_missing){
rownames(current_fcasts) <- c(rownames(target_variables), rownames(factors))
}else{
rownames(current_fcasts) <- c(rownames(target_variables), rownames(quarterly_predictors), rownames(factors))
}
return_object[[current_target]] <- current_fcasts
names(return_object)[current_target] <- paste0("Single Predictor Forecasts ", rownames(target_variables)[current_target], collapse = "")
fcasts[current_target, (max_fcast_horizon - min(min_fcast_horizons) - length(rel_fcast_horizons) + 2):(max_fcast_horizon - min(min_fcast_horizons) + 1)] <-
colMeans(current_fcasts, na.rm = TRUE)
# Start ARDL estimation loop over the predictor #
}
# End ARDL estimation loop over the target variables #
rownames(fcasts) <- rownames(target_variables)
return_object[[no_of_target_vars + 1]] <- fcasts
names(return_object)[no_of_target_vars + 1] <- "Avg. Point Forecast"
return(return_object)
}
Rcpp::sourceCpp("./src/ARDL.cpp")
no_of_factors <- dim(factors)[1]
no_of_target_vars <- dim(target_variables)[1]
qtrly_predictors_missing <- is.null(quarterly_predictors)
if(qtrly_predictors_missing){
no_of_qrtly_vars <- 0
}else{
no_of_qrtly_vars <- dim(quarterly_predictors)[1]
}
no_of_vars  <- no_of_qrtly_vars + no_of_target_vars
no_of_qrtly_obs <- (dim(factors)[2] - 2) / 3
min_fcast_horizons <- ifelse(target_variable_delay == 0,
1,
-floor(target_variable_delay / 3) + 1)
return_object <- list()
# Store all monthly predictors and the monthly factors in a single matrix
all_qtrly_data_delay <- c(floor(c(target_variable_delay, quarterly_delay) / 3), rep(0, no_of_factors))
all_qrtly_data <- matrix(NaN, no_of_vars + no_of_factors, no_of_qrtly_obs)
for(t in seq(5, dim(factors)[2], 3)){
all_qrtly_data[1:no_of_target_vars, (t - 2)/3] <- target_variables[, t]
if(!qtrly_predictors_missing){
all_qrtly_data[(no_of_target_vars + 1):(no_of_target_vars + no_of_qrtly_vars),
(t - 2)/3] <- quarterly_predictors[, t]
}
all_qrtly_data[(no_of_target_vars + no_of_qrtly_vars + 1):(no_of_vars + no_of_factors),
(t - 2)/3] <- rowSums(cbind(1/3 * factors[, t, drop = FALSE],
2/3 * factors[, t - 1, drop = FALSE],
1 * factors[, t - 2, drop = FALSE],
2/3 * factors[, t - 3, drop = FALSE],
1/3 * factors[, t - 4, drop = FALSE]),
na.rm = TRUE)
}
fcasts <- matrix(NaN, no_of_target_vars, max_fcast_horizon - min(min_fcast_horizons) + 1)
for(current_target in 1:no_of_target_vars){
# Start ARDL estimation loop over the predictor #
current_fcasts <- matrix(NaN, no_of_vars + no_of_factors, max_fcast_horizon - min_fcast_horizons[current_target] + 1)
for(current_predictor in 1:(no_of_vars + no_of_factors)){
if(current_target == current_predictor){
next # Skip using the current target_variable as a single predictor as its always included as predictor
}
if(all_qtrly_data_delay[current_target] < all_qtrly_data_delay[current_predictor]){
next # Skip a predictor if it is dalyed further back compared to the target variable (we do not expect forecasting gains from using variables that are further behind then the target)
}
rel_fcast_horizons <- min_fcast_horizons[current_target]:max_fcast_horizon + all_qtrly_data_delay[current_predictor]
for(h in rel_fcast_horizons){
# Fit the model for the specific forecasting horizon
horizon_adjustment <- which(rel_fcast_horizons == h)
horizon_specific_target <- matrix(
all_qrtly_data[current_target,
(horizon_adjustment + 1):(no_of_qrtly_obs - all_qtrly_data_delay[current_target])],
ncol = 1)
horizon_specific_ar_lag <- matrix(
all_qrtly_data[current_target,
1:(no_of_qrtly_obs - all_qtrly_data_delay[current_target] - horizon_adjustment)],
ncol = 1)
horizon_specific_predictor <- matrix(
all_qrtly_data[current_predictor,
(horizon_adjustment + 1 - h):(no_of_qrtly_obs - all_qtrly_data_delay[current_target] - h)],
ncol = 1)
ardl_fit <- runARDL(horizon_specific_target,
horizon_specific_ar_lag,
horizon_specific_predictor,
max(max_ar_lag_order - max(h, 0), 1),
max(max_predictor_lag_order - max(h, 0), 1),
lag_estim_criterion)
# Forecast
forecast_predictors <- matrix(1, sum(ardl_fit$optimL_lag_order) + 3, 1) # Add three for the intercept and the "contemporaenous" observations
forecast_predictors[2:(ardl_fit$optimL_lag_order[1] + 2), ] <-
head(all_qrtly_data[current_target,
(no_of_qrtly_obs - all_qtrly_data_delay[current_target]):1],
ardl_fit$optimL_lag_order[1] + 1)
forecast_predictors[(ardl_fit$optimL_lag_order[1] + 3):(ardl_fit$optimL_lag_order[1] + ardl_fit$optimL_lag_order[2] + 3), ] <-
head(all_qrtly_data[current_predictor,
(no_of_qrtly_obs - all_qtrly_data_delay[current_predictor]):1],
ardl_fit$optimL_lag_order[2] + 1)
current_fcasts[current_predictor, which(rel_fcast_horizons == h)] <-
matrix(ardl_fit$coefficients, nrow = 1) %*% forecast_predictors
}
# End loop over the forecasting horizons #
}
# Store the final point forecast using simple forecast averaging for each target
if(qtrly_predictors_missing){
rownames(current_fcasts) <- c(rownames(target_variables), rownames(factors))
}else{
rownames(current_fcasts) <- c(rownames(target_variables), rownames(quarterly_predictors), rownames(factors))
}
return_object[[current_target]] <- current_fcasts
names(return_object)[current_target] <- paste0("Single Predictor Forecasts ", rownames(target_variables)[current_target], collapse = "")
fcasts[current_target, (max_fcast_horizon - min(min_fcast_horizons) - length(rel_fcast_horizons) + 2):(max_fcast_horizon - min(min_fcast_horizons) + 1)] <-
colMeans(current_fcasts, na.rm = TRUE)
# Start ARDL estimation loop over the predictor #
}
rownames(fcasts) <- rownames(target_variables)
return_object[[no_of_target_vars + 1]] <- fcasts
names(return_object)[no_of_target_vars + 1] <- "Avg. Point Forecast"
forecasts <- forecastWrapper(target_variables = target_variables, quarterly_predictors = quarterly_predictors,
factors = factors, target_variable_delay = target_variable_delay,
quarterly_delay = quarterly_delay, lag_estim_criterion = lag_estim_criterion,
max_fcast_horizon = effective_fcast_horizon, max_ar_lag_order = max_ar_lag_order,
max_predictor_lag_order = max_predictor_lag_order)
forecasts
# Create nice result object
result <- list()
# Store the forecast results
result[[1]] <- list()
names(result)[1] <- "Forecasts"
# Store forecasts together with the quarterly target series
qtrly_series <- data[which(month(time(data)) %in% c(3, 6, 9, 12)), variables_of_interest]
forecast_and_series <- matrix(NaN, dim(qtrly_series)[1] + max_fcast_horizon, 2 * length(variables_of_interest))
forecast_and_series
qtrly_series
# Store forecasts together with the quarterly target series
qtrly_series <- data[which(month(time(data)) %in% c(3, 6, 9, 12)), variables_of_interest, drop = FALSE]
qtrly_series
# Store forecasts together with the quarterly target series
qtrly_series <- data[which(month(time(data)) %in% c(3, 6, 9, 12)), variables_of_interest, drop = FALSE]
forecast_and_series <- matrix(NaN, dim(qtrly_series)[1] + max_fcast_horizon, 2 * length(variables_of_interest))
colnames(forecast_and_series) <- paste0(1:(2 * length(variables_of_interest)))
for(n in 1:length(variables_of_interest)){
forecast_and_series[1:dim(qtrly_series)[1], 2*n - 1] <- qtrly_series[, n]
forecast_and_series[(dim(qtrly_series)[1] - delay[variables_of_interest[n]] / 3 + 1):dim(forecast_and_series)[1], 2*n] <-
forecasts$`Avg. Point Forecast`[n, (dim(forecasts$`Avg. Point Forecast`)[2] - delay[variables_of_interest[n]] / 3 - max_fcast_horizon + 1):dim(forecasts$`Avg. Point Forecast`)[2]]
colnames(forecast_and_series)[2*n - 1] <- colnames(data)[variables_of_interest[n]]
colnames(forecast_and_series)[2*n] <- paste0("Fcast ", colnames(data)[variables_of_interest[n]])
}
result$Forecasts <- as.zoo(ts(forecast_and_series, start = c(year(time(data)[1]),
quarter(time(data)[1])), frequency = 4))
result$Forecasts
result$`Single Predictor Forecasts` <- list()
for(i in 1:length(variables_of_interest)){
result$`Single Predictor Forecasts`[[i]] <-
as.zoo(ts(t(forecasts[[i]]),
end = c(year(time(result$Forecasts)[dim(result$Forecasts)[1]]),
quarter(time(result$Forecasts)[dim(result$Forecasts)[1]])),
frequency = 4
))
names(result$`Single Predictor Forecasts`)[i] <- names(forecasts)[i]
}
# Store the forecast results
result$`SDFM Fit` <- SDFM_fit
class(result) <- "SDFMnowcast"
x <- result
print(x$Forecasts)
out_list <- list()
# Single Predictor Density Plots
absolute_fcast_date <- time(x$`SDFM Fit`$data)[dim(x$`SDFM Fit`$data)[1]]
for(h in 1:(dim(x$Forecasts)[2] / 2)){
current_single_pred_raw <- x$`Single Predictor Forecasts`[[h]]
current_single_pred <- na.omit(t(coredata(current_single_pred_raw)))
plot_list <- list()
for(horizon in 1:dim(current_single_pred)[2]){
data_df <- data.frame(
Series = rownames(current_single_pred),
Value = as.numeric(current_single_pred[, horizon])
)
data_df$Series <- factor(data_df$Series, levels = rownames(current_single_pred))
relative_fcast_date <- as.yearqtr(time(current_single_pred_raw)[horizon])
current_horizon <- 4 * (relative_fcast_date - as.yearqtr(absolute_fcast_date))
max_density <- max(density(data_df$Value)$y)
current_density_plot <- ggplot(data_df, aes(x = Value)) +
geom_density(fill = "#88ccee", alpha = 0.6, color = "#332288") +
geom_vline(xintercept = mean(data_df$Value), colour = "#882255",
lty = 1) +
geom_text(label = "Mean", y = max_density * 0.7,
x = mean(data_df$Value ) + 0.1 * sqrt(var(data_df$Value)),
colour = "#882255") +
geom_vline(xintercept = median(data_df$Value), colour = "#117733",
lty = 2) +
geom_text(label = "Median", y = max_density * 0.8,
x = median(data_df$Value ) - 0.12 * sqrt(var(data_df$Value)),
colour = "#117733") +
geom_point(aes(y = 0), size = 2) +
geom_text(aes(label = Series, y  = 0.00), nudge_y = max_density * 0.2,
size = 3.5, angle = 90, color = "black") +
labs(title = paste0(ifelse(current_horizon >= 0,
ifelse(current_horizon == 0,
"Nowcast", paste0(current_horizon, "-step ahead Forecast")),
paste0(-current_horizon, "-step back Backcast")),
" for ", relative_fcast_date),
x = "Predicted Value", y = ""
) +
theme_minimal()
plot_list[[horizon]] <- current_density_plot
}
out_list[[h]] <- patchwork::wrap_plots(plot_list, ncol = 2)
names(out_list)[h] <- paste0("Single Pred. Fcast Density Plots ", colnames(x$Forecasts)[2 * h - 1])
}
h
current_single_pred_raw <- x$`Single Predictor Forecasts`[[h]]
current_single_pred <- na.omit(t(coredata(current_single_pred_raw)))
current_single_pred_raw
current_single_pred
dim(x$Forecasts)[2]
dim(x$Forecasts)[2] <= 2
dim(x$Forecasts)[2] >= 2
# Single Predictor Density Plots
absolute_fcast_date <- time(x$`SDFM Fit`$data)[dim(x$`SDFM Fit`$data)[1]]
if(dim(x$Forecasts)[2] >= 2){
for(h in 1:(dim(x$Forecasts)[2] / 2)){
current_single_pred_raw <- x$`Single Predictor Forecasts`[[h]]
current_single_pred <- na.omit(t(coredata(current_single_pred_raw)))
plot_list <- list()
for(horizon in 1:dim(current_single_pred)[2]){
data_df <- data.frame(
Series = rownames(current_single_pred),
Value = as.numeric(current_single_pred[, horizon])
)
data_df$Series <- factor(data_df$Series, levels = rownames(current_single_pred))
relative_fcast_date <- as.yearqtr(time(current_single_pred_raw)[horizon])
current_horizon <- 4 * (relative_fcast_date - as.yearqtr(absolute_fcast_date))
max_density <- max(density(data_df$Value)$y)
current_density_plot <- ggplot(data_df, aes(x = Value)) +
geom_density(fill = "#88ccee", alpha = 0.6, color = "#332288") +
geom_vline(xintercept = mean(data_df$Value), colour = "#882255",
lty = 1) +
geom_text(label = "Mean", y = max_density * 0.7,
x = mean(data_df$Value ) + 0.1 * sqrt(var(data_df$Value)),
colour = "#882255") +
geom_vline(xintercept = median(data_df$Value), colour = "#117733",
lty = 2) +
geom_text(label = "Median", y = max_density * 0.8,
x = median(data_df$Value ) - 0.12 * sqrt(var(data_df$Value)),
colour = "#117733") +
geom_point(aes(y = 0), size = 2) +
geom_text(aes(label = Series, y  = 0.00), nudge_y = max_density * 0.2,
size = 3.5, angle = 90, color = "black") +
labs(title = paste0(ifelse(current_horizon >= 0,
ifelse(current_horizon == 0,
"Nowcast", paste0(current_horizon, "-step ahead Forecast")),
paste0(-current_horizon, "-step back Backcast")),
" for ", relative_fcast_date),
x = "Predicted Value", y = ""
) +
theme_minimal()
plot_list[[horizon]] <- current_density_plot
}
out_list[[h]] <- patchwork::wrap_plots(plot_list, ncol = 2)
names(out_list)[h] <- paste0("Single Pred. Fcast Density Plots ", colnames(x$Forecasts)[2 * h - 1])
}
}
dim(x$Forecasts)[2] >= 2
# Single Predictor Density Plots
absolute_fcast_date <- time(x$`SDFM Fit`$data)[dim(x$`SDFM Fit`$data)[1]]
if(dim(x$Forecasts)[2] > 2){
for(h in 1:(dim(x$Forecasts)[2] / 2)){
current_single_pred_raw <- x$`Single Predictor Forecasts`[[h]]
current_single_pred <- na.omit(t(coredata(current_single_pred_raw)))
plot_list <- list()
for(horizon in 1:dim(current_single_pred)[2]){
data_df <- data.frame(
Series = rownames(current_single_pred),
Value = as.numeric(current_single_pred[, horizon])
)
data_df$Series <- factor(data_df$Series, levels = rownames(current_single_pred))
relative_fcast_date <- as.yearqtr(time(current_single_pred_raw)[horizon])
current_horizon <- 4 * (relative_fcast_date - as.yearqtr(absolute_fcast_date))
max_density <- max(density(data_df$Value)$y)
current_density_plot <- ggplot(data_df, aes(x = Value)) +
geom_density(fill = "#88ccee", alpha = 0.6, color = "#332288") +
geom_vline(xintercept = mean(data_df$Value), colour = "#882255",
lty = 1) +
geom_text(label = "Mean", y = max_density * 0.7,
x = mean(data_df$Value ) + 0.1 * sqrt(var(data_df$Value)),
colour = "#882255") +
geom_vline(xintercept = median(data_df$Value), colour = "#117733",
lty = 2) +
geom_text(label = "Median", y = max_density * 0.8,
x = median(data_df$Value ) - 0.12 * sqrt(var(data_df$Value)),
colour = "#117733") +
geom_point(aes(y = 0), size = 2) +
geom_text(aes(label = Series, y  = 0.00), nudge_y = max_density * 0.2,
size = 3.5, angle = 90, color = "black") +
labs(title = paste0(ifelse(current_horizon >= 0,
ifelse(current_horizon == 0,
"Nowcast", paste0(current_horizon, "-step ahead Forecast")),
paste0(-current_horizon, "-step back Backcast")),
" for ", relative_fcast_date),
x = "Predicted Value", y = ""
) +
theme_minimal()
plot_list[[horizon]] <- current_density_plot
}
out_list[[h]] <- patchwork::wrap_plots(plot_list, ncol = 2)
names(out_list)[h] <- paste0("Single Pred. Fcast Density Plots ", colnames(x$Forecasts)[2 * h - 1])
}
}
insample_plots <- plot(x$`SDFM Fit`)
out_list$`Factor Time Series Plots` <- insample_plots$`Factor Time Series Plots`
out_list$`Loading Matrix Heatmap` <- insample_plots$`Loading Matrix Heatmap`
out_list$`Meas. Error Var.-Cov. Matrix Heatmap` <- insample_plots$`Meas. Error Var.-Cov. Matrix Heatmap`
frequency[variables_of_interest] != 4
# Build
devtools::build()
