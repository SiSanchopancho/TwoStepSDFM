alpha <- c(0.1,0.1,0.075,0.075)
delta1 <- 0.1
delta2 <- -0.2
lambda <- 0.3
tau <- rexp(T+100, rate = 1/lambda)
mean(tau)
#Omega <- diag(c(0.5,0.5,0.25,0.25))
#Omega <- as.matrix(bdiag(replicate(2,diag(c(0.5,0.25)),simplify=FALSE)))
#fatdiag(Omega, steps=2)
Omega1 <- diag(c(0.05,0.05))
Omega2 <- diag(c(0.025,0.025))
Omega <- as.matrix(bdiag(Omega1,Omega2))
e <- rmvnorm(T+100, mean=rep(0,2*M), sigma=Omega, method="chol")
mt <- r
for (i in 2:(T+100)) {
mt[i,] <- mt[i-1,] + sigma * tau[i]^delta1 * r[i,]
}
ct <- matrix(rep(c(-0.2,0.2),2), nrow=T+100, ncol=2*M, byrow=T)
# quotes
q <- ct + mt %*%  rep(1,2*M) + (r * sigma * tau^delta2) %*%  alpha + e
q <- q[-(1:100),]
tau <- tau[-(1:100)]
# bid > ask?
sum(q[,2] - q[,1] < 0)
sum(q[,4] - q[,3] < 0)
ts.plot(q)
spread <- colMeans(q[,seq(2,2*M, by=2)] - q[,seq(1,2*M-1, by=2)])
start <- c(spread, as.vector(alpha), t(chol(Omega1))[lower.tri(t(chol(Omega1)), diag=TRUE)],
t(chol(Omega2))[lower.tri(t(chol(Omega2)), diag=TRUE)], sigma, delta1, delta2)
ind.mat <- matrix(TRUE, nrow=T, ncol=M)
ptm <- proc.time()
start_alt <- start + rnorm(length(start))
estResults <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 10e-8, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_NELDERMEAD", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
proc.time() - ptm
ptm <- proc.time()
start_alt <- start + rnorm(length(start))
estResults <- try(QuoteDynamics::quoteDynOptim(start = start_alt, X = q, tau = tau, ident_mat = ind.mat,
xtol = 10e-8, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_NELDERMEAD", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
proc.time() - ptm
estResults$estimate
start
start_alt
estResults <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 10e-8, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_NELDERMEAD", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 10e-20, stop_val = 10e-20, max_eval = 30000,
algorithm = "LN_NELDERMEAD", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults <- try(QuoteDynamics::quoteDynOptim(start = start_alt, X = q, tau = tau, ident_mat = ind.mat,
xtol = 10e-20, stop_val = 10e-20, max_eval = 30000,
algorithm = "LN_NELDERMEAD", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults <- try(QuoteDynamics::quoteDynOptim(start = start_alt, X = q, tau = tau, ident_mat = ind.mat,
xtol = 10e-20, stop_val = 10e-20, max_eval = 30000,
algorithm = "LN_COBYLA", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults$estimate
start
start_alt
require(mvtnorm)
require(MASS)
library(Matrix)
require(diagonals)
library(QuoteDynamics)
rm(list=ls())
#--------------------------------------------------------------------------
# Multivariate Kalman filter
#--------------------------------------------------------------------------
lnlt <- function(b,y,tau,ind.mat) {
# dimension of the observations: 2*M
# dimension of the state variable: 2
M <- ncol(y)/2
# Parameters
spread <- b[1:M]
ct <- c(-spread[1]/2,spread[1]/2)
for (i in 2:M) ct <- c(ct, -spread[i]/2,spread[i]/2)
alpha <- b[(M+1):(3*M)]
b <- b[-(1:(3*M))]
C.mat <- matrix(0, nrow=2, ncol=2)
C.mat[lower.tri(C.mat, diag=TRUE)] <- b[1:3]
b <- b[-(1:3)]
Omega <- C.mat %*% t(C.mat)
GGt <- as.matrix(bdiag(Omega))
for (i in 2:M) {
C.mat <- matrix(0, nrow=2, ncol=2)
C.mat[lower.tri(C.mat, diag=TRUE)] <- b[1:3]
b <- b[-(1:3)]
Omega <- C.mat %*% t(C.mat)
GGt <- as.matrix(bdiag(GGt,Omega))
}
dt <- c(0,0)
Tt <- matrix(c(1,0,
0,0), nrow=2, ncol=2)
sigma <- b[1]
delta1 <- b[2]
delta2 <- b[3]
# Allocate arrays
t <- nrow(y)
n <- ncol(y)
lnl <- rep(0, t)
# Recursions of the Kalman Filter
# Initialisation
st <- rep(0, 2)
Pt <- diag(2)*1000
Zt <- cbind(1,alpha*tau[1]^delta2*sigma)
# Observation
# conditional mean of yt
mut <- ct + Zt %*% st
# conditional variance of yt
Ft <- Zt %*% Pt %*% t(Zt) + GGt
# forecast error
vt <- y[1,] - mut
lnl[1] <- - 0.5*n*log(2*pi) - 0.5*log(det(Ft)) - 0.5*t(vt) %*% solve(Ft) %*% vt
# Kalman gain
Kt <- Pt %*% t(Zt) %*% solve(Ft)
# latent state
s0 <- st + Kt %*% vt
# conditional variance
P0 <- Pt - Pt %*% t(Zt) %*% t(Kt)
# Main loop over observations
for (i in 2:t) {
# construct selection matrix
S <- diag(2*M)
index <- c()
for (j in 1:M) {
if (ind.mat[i,j] == FALSE) {index <- c(index, ((2*j-1):(2*j)))}
}
if(!is.null(index)){
S <- S[-index, ]
}
Zt <- S %*% cbind(1,alpha*tau[i]^delta2*sigma)
H <- matrix(c(0,sigma*tau[i]^delta1,
0,1), nrow=2, ncol=2, byrow=TRUE)
# updating
st <- dt + Tt %*% s0
Pt <- Tt %*% P0 %*% t(Tt) + H %*% t(H)
# Observation
# conditional mean of yt
mut <- S %*% ct + Zt %*% st
# conditional variance of yt
Ft <- Zt %*% Pt %*% t(Zt) + S %*% GGt %*% t(S)
# forecast error
vt <- S %*% y[i,] - mut
lnl[i] <- - 0.5*n*log(2*pi) - 0.5*log(det(Ft)) - 0.5*t(vt) %*% solve(Ft) %*% vt
# updating
# Kalman gain
Kt <- Pt %*% t(Zt) %*% solve(Ft)
# latent state
s0 <- st + Kt %*% vt
# conditional variance
P0 <- Pt - Pt %*% t(Zt) %*% t(Kt)
}
return(lnl)
}
neglog <- function(b,y,tau,ind.mat) {
lf <- -mean( lnlt(b,y,tau,ind.mat) )
return(lf)
}
set.seed(12345)
R <- 100
par.mat <- matrix(NA, nrow=R, ncol=15)
# for (s in 1:R) {
for (s in 1:1) {
T <- 1000
# M markets
M <- 2
# number of quote (bid/ask) time series: 2*M
r <- matrix(rnorm(T+100,0,1), nrow=T+100, ncol=1)
sigma <- 0.1
alpha <- c(0.1,0.1,0.075,0.075)
delta1 <- 0.1
delta2 <- -0.2
lambda <- 0.3
tau <- rexp(T+100, rate = 1/lambda)
mean(tau)
#Omega <- diag(c(0.5,0.5,0.25,0.25))
#Omega <- as.matrix(bdiag(replicate(2,diag(c(0.5,0.25)),simplify=FALSE)))
#fatdiag(Omega, steps=2)
Omega1 <- diag(c(0.05,0.05))
Omega2 <- diag(c(0.025,0.025))
Omega <- as.matrix(bdiag(Omega1,Omega2))
e <- rmvnorm(T+100, mean=rep(0,2*M), sigma=Omega, method="chol")
mt <- r
for (i in 2:(T+100)) {
mt[i,] <- mt[i-1,] + sigma * tau[i]^delta1 * r[i,]
}
ct <- matrix(rep(c(-0.2,0.2),2), nrow=T+100, ncol=2*M, byrow=T)
# quotes
q <- ct + mt %*%  rep(1,2*M) + (r * sigma * tau^delta2) %*%  alpha + e
q <- q[-(1:100),]
tau <- tau[-(1:100)]
# bid > ask?
sum(q[,2] - q[,1] < 0)
sum(q[,4] - q[,3] < 0)
ts.plot(q)
spread <- colMeans(q[,seq(2,2*M, by=2)] - q[,seq(1,2*M-1, by=2)])
start <- c(spread, as.vector(alpha), t(chol(Omega1))[lower.tri(t(chol(Omega1)), diag=TRUE)],
t(chol(Omega2))[lower.tri(t(chol(Omega2)), diag=TRUE)], sigma, delta1, delta2)
ind.mat <- matrix(TRUE, nrow=T, ncol=M)
ptm <- proc.time()
estResults <- optim(start, neglog, y=q, tau=tau, ind.mat=ind.mat, method="Nelder-Mead", hessian=FALSE)
proc.time() - ptm
if (inherits(estResults, "try-error")) {
# Error
bhat <- start
error <- 1
} else {
bhat <- estResults$par
error <- 0
}
par.mat[s,] <- bhat
}
estResults
library(QuoteDynamics)
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start_alt, X = q, tau = tau, ident_mat = ind.mat,
xtol = 0, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_COBYLA", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 0, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_COBYLA", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-300, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_COBYLA", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults
PrintAlgorithms()
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-300, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_NELDERMEAD", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults
estResults <- optim(start, neglog, y=q, tau=tau, ind.mat=ind.mat, method="Nelder-Mead", hessian=FALSE,
control = list(maxit = 10000, reltol = 1e-8))
estResults
install.packages("nloptr")
library(nloptr)
??nloptr
?nloptr
opts <- list("algorithm" = "NLOPT_LD_LBFGS",
"xtol_rel" = 1.0e-8)
estResults_nloptr <- nloptr(start, neglog, opts, y=q, tau=tau, ind.mat=ind.mat)
neglog
estResults_nloptr <- nloptr(c0 = start, eval_f = neglog, opts = opts, y=q, tau=tau, ind.mat=ind.mat)
estResults_nloptr <- nloptr(x0 = start, eval_f = neglog, opts = opts, y=q, tau=tau, ind.mat=ind.mat)
opts <- list("algorithm" = "NLOPT_LD_NELDERMEAD",
"xtol_rel" = 1.0e-8)
estResults_nloptr <- nloptr(x0 = start, eval_f = neglog, opts = opts, y=q, tau=tau, ind.mat=ind.mat)
opts <- list("algorithm" = "NLOPT_LN_NELDERMEAD",
"xtol_rel" = 1.0e-8)
estResults_nloptr <- nloptr(x0 = start, eval_f = neglog, opts = opts, y=q, tau=tau, ind.mat=ind.mat)
estResults_nloptr
opts <- list("algorithm" = "NLOPT_LN_NELDERMEAD",
"xtol_rel" = 0.0)
estResults_nloptr <- nloptr(x0 = start, eval_f = neglog, opts = opts, y=q, tau=tau, ind.mat=ind.mat)
estResults_nloptr
estResults
opts <- list(algorithm = "NLOPT_LN_SBPLX", maxeval = 10000, xtol_rel = 1e-6)
estResults_nloptr <- nloptr(x0 = start, eval_f = neglog, opts = opts, y=q, tau=tau, ind.mat=ind.mat)
estResults_nloptr
start
start_alt <- start + rnorm(length(start))
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-300, stop_val = 10e-8, max_eval = 30000,
algorithm = "LN_SBPLX", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
proc.time() - ptm
estResults$estimate
ptm <- proc.time()
start_alt <- start + rnorm(length(start))
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-6, stop_val = 10e-8, max_eval = 10000,
algorithm = "LN_SBPLX", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
proc.time() - ptm
estResults_cpp$estimate
estResults_nloptr$x0
estResults_nloptr
estResults_nloptr$solution
estResults_nloptr$solution
estResults_cpp$estimate
estResults_nloptr$solution
start
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-6, stop_val = 10e-300, max_eval = 10000,
algorithm = "LN_SBPLX", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-8, stop_val = 10e-8, max_eval = 10000,
algorithm = "LN_SBPLX", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
estResults_cpp <- try(QuoteDynamics::quoteDynOptim(start = start, X = q, tau = tau, ident_mat = ind.mat,
xtol = 1e-10, stop_val = 10e-8, max_eval = 10000,
algorithm = "LN_SBPLX", hessian = FALSE,
step_size = 1e-18, verbose = TRUE))
?sparseDFM::sparseDFM
data <- MASS::mvrnorm(100, rep(0, 15), diag(15))
R <- 2
alphas <- logspace(-2, 3, 100)
fit_bic_validation <- sparseDFM(X = data, r = R, q = 0, alphas = alphas, alg = "EM-sparse", err = "AR1", standardize = FALSE)
library(sparseDFM)
alphas <- logspace(-2, 3, 100)
fit_bic_validation <- sparseDFM(X = data, r = R, q = 0, alphas = alphas, alg = "EM-sparse", err = "AR1", standardize = FALSE)
fit <- sparseDFM(X = data, r = R, q = 0, alphas = alphas[which.min(fit_bic_validation$em$bic)], alg = "EM-sparse", err = "AR1", standardize = FALSE)
# Simulate the posterior of the factors and the error terms
factors <- fit$state$factors
# Simulate the posterior of the factors and the error terms
factors <- fit$state$factors
factors
?array
# Simulate the posterior of the factors and the error terms
draws <- 10000
factors <- fit$state$factors
errors <- fit$state$errors
factor_dist <- array(NaN, dim = c(dim(factors), draws))
factor_dist
dim(factor_dist)
factor_dist[t, r, ]
t <- 1
r <- 1
factor_dist[t, , ]
# Simulate the posterior of the factors and the error terms
draws <- 10
factors <- fit$state$factors
errors <- fit$state$errors
factor_dist <- array(NaN, dim = c(dim(factors), draws))
factor_dist[t, , ]
factors[t, ]
factor_var_cov <- fit$state$factors.cov
factor_var_cov
factor_var_cov[, , t]
MASS::mvrnorm(draws, factors[t, ], factor_var_cov[, , t])
factor_dist[t, , ] <- t(MASS::mvrnorm(draws, factors[t, ], factor_var_cov[, , t]))
factor_dist[t, , ]
factor_lower_ci <- matrix(NaN, dim(factors))
factor_lower_ci
dim(factors)
factor_lower_ci
dim(errors)[2]
factor_upper_ci <- matrix(NaN, T, R)
crr_factor_dist <- t(MASS::mvrnorm(draws, factors[t, ], fit$state$factors.cov[, , t]))
crr_factor_dist
factor_lower_ci <- sort(crr_factor_dist)
factor_lower_ci
crr_factor_dist
?quantile
crr_factor_dist <- MASS::mvrnorm(draws, factors[t, ], fit$state$factors.cov[, , t])
crr_factor_dist
factor_lower_ci <- sort(crr_factor_dist[, r], 0.05)
factor_lower_ci
factor_lower_ci <- sort(crr_factor_dist[, r], probs = c(0.05))
factor_lower_ci
# Simulate the posterior of the factors and the error terms
draws <- 10
factors <- fit$state$factors
errors <- fit$state$errors
N <- dim(errors)[2]
R <- dim(factors)[2]
T <- dim(factors)[1]
factor_lower_ci <- matrix(NaN, T, R)
factor_upper_ci <- matrix(NaN, T, R)
errors_lower_ci <- matrix(NaN, T, N)
errors_upper_ci <- matrix(NaN, T, N)
factor_lower_ci[t, r] <- quantile(crr_factor_dist[, r], , probs = c(0.05))
factor_lower_ci
for(r in 1:R){
factor_lower_ci[t, r] <- quantile(crr_factor_dist[, r], , probs = c(0.05))
}
factor_lower_ci
factor_upper_ci[t, r] <- quantile(crr_factor_dist[, r], , probs = c(0.95))
factor_upper_ci
for(r in 1:R){
factor_lower_ci[t, r] <- quantile(crr_factor_dist[, r], , probs = c(0.05))
factor_upper_ci[t, r] <- quantile(crr_factor_dist[, r], , probs = c(0.95))
}
factor_upper_ci
crr_errors_dist <- MASS::mvrnorm(draws, errors[t, ], fit$state$errors.cov[, , t])
crr_errors_dist
for(n in 1:N){
errors_lower_ci[t, n] <- quantile(crr_errors_dist[, n], probs = c(0.05))
errors_upper_ci[t, n] <- quantile(crr_errors_dist[, n], probs = c(0.95))
}
errors_lower_ci
# Simulate the posterior of the factors and the error terms
draws <- 10000
factors <- fit$state$factors
errors <- fit$state$errors
N <- dim(errors)[2]
R <- dim(factors)[2]
T <- dim(factors)[1]
factor_lower_ci <- matrix(NaN, T, R)
factor_upper_ci <- matrix(NaN, T, R)
errors_lower_ci <- matrix(NaN, T, N)
errors_upper_ci <- matrix(NaN, T, N)
for(t in 1:T){
crr_factor_dist <- MASS::mvrnorm(draws, factors[t, ], fit$state$factors.cov[, , t])
crr_errors_dist <- MASS::mvrnorm(draws, errors[t, ], fit$state$errors.cov[, , t])
for(r in 1:R){
factor_lower_ci[t, r] <- quantile(crr_factor_dist[, r], probs = c(0.05))
factor_upper_ci[t, r] <- quantile(crr_factor_dist[, r], probs = c(0.95))
}
for(n in 1:N){
errors_lower_ci[t, n] <- quantile(crr_errors_dist[, n], probs = c(0.05))
errors_upper_ci[t, n] <- quantile(crr_errors_dist[, n], probs = c(0.95))
}
}
errors_upper_ci
ci <- 0.95
bound <- (1 - ci() / 2
factors <- fit$state$factors
bound <- (1 - ci / 2
factors <- fit$state$factors
bound <- (1 - ci) / 2
bound
# Simulate the posterior of the factors and the error terms
draws <- 100000
bound <- (1 - ci) / 2
factors <- fit$state$factors
errors <- fit$state$errors
N <- dim(errors)[2]
R <- dim(factors)[2]
T <- dim(factors)[1]
factor_lower_ci <- matrix(NaN, T, R)
factor_upper_ci <- matrix(NaN, T, R)
errors_lower_ci <- matrix(NaN, T, N)
errors_upper_ci <- matrix(NaN, T, N)
for(t in 1:T){
crr_factor_dist <- MASS::mvrnorm(draws, factors[t, ], fit$state$factors.cov[, , t])
crr_errors_dist <- MASS::mvrnorm(draws, errors[t, ], fit$state$errors.cov[, , t])
for(r in 1:R){
factor_lower_ci[t, r] <- quantile(crr_factor_dist[, r], probs = c(bound))
factor_upper_ci[t, r] <- quantile(crr_factor_dist[, r], probs = c(1 - bound))
}
for(n in 1:N){
errors_lower_ci[t, n] <- quantile(crr_errors_dist[, n], probs = c(bound))
errors_upper_ci[t, n] <- quantile(crr_errors_dist[, n], probs = c(1 - bound))
}
}
errors_lower_ci
factor_lower_ci
A <- matrix(c(0.9, -0.1, -0.1, 0.9))
A
A <- matrix(c(0.9, -0.1, -0.1, 0.9), 2, 2)
A
eigen(A)
B <- matrix(c(1, 0.9, 0.9, 0.85), 2, 2)
B
chol(B)
library(TwoStepSDFM)
library(testthat)
library(TwoStepSDFM)
library(testthat)
library(zoo)
library(xts)
library(lubridate)
library(ggplot2)
# SPDX-License-Identifier: GPL-3.0-or-later
#
#  Copyright \u00A9 2024 Domenic Franjic
#
#  This file is part of TwoStepSDFM.
#
#  TwoStepSDFM is free software: you can redistribute
#  it and/or modify it under the terms of the GNU General Public License as
#  published by the Free Software Foundation, either version 3 of the License,
#  or (at your option) any later version.
#
#  TwoStepSDFM is distributed in the hope that it
#  will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
#  of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with TwoStepSDFM. If not, see <https://www.gnu.org/licenses/>.
# Convinient package builder #
# Load libraries
library(rstudioapi)
library(roxygen2)
# Set directory
setwd(dirname(getActiveDocumentContext()$path))
rm(list = ls())
# Clean up
unlink("src/*.o")
unlink("src/*.so")
unlink("src/*.dll")
devtools::clean_dll()
devtools::clean_vignettes()
devtools::build_vignettes()
# Compile Rcpp attributes
Rcpp::compileAttributes()
# Install the package
# devtools::install()
devtools::check()
# Build
devtools::build()
# Load libraries
library(rstudioapi)
library(roxygen2)
# Set directory
setwd(dirname(getActiveDocumentContext()$path))
rm(list  = ls())
output <- system2("R", args = c("CMD", "INSTALL", "../TwoStepSDFM_0.1.2.tar.gz"),
stdout = TRUE, stderr = TRUE)
writeLines(output, "compilation_log.txt")
